{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using SHAFTS in Malasya\n",
    "\n",
    "This is a simple test example of using the Shafts package in a region in Kuala Lumpur in Malasya. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from shafts.inference import pred_height_from_tiff_DL_patch_MTL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter of SEResNetMTL:  1418962  Trainable parameter of SEResNetMTL:  1418962\n"
     ]
    }
   ],
   "source": [
    "target_res_mapping = {100: 0.0009, 250: 0.00225, 500: 0.0045, 1000: 0.009}      # map target resolution in meters to degrees\n",
    "\n",
    "# ---define some variables for the path look-ups (optional)\n",
    "tmp_dir = \"tmp\"           # path of a directory for temporary results saving during prediction\n",
    "pt_prefix = \"DL_run\"      # path prefix for pretrained models\n",
    "case_prefix = os.path.dirname(os.path.dirname(os.path.abspath(sys.argv[1])))  # path prefix for input data and results of the case\n",
    "backbone = \"senet\"        # the backbone of prediction models\n",
    "\n",
    "# ---specify the lower bound and upper bound of building height prediction by `h_min` and `h_max`, respectively.\n",
    "h_min = 2.0\n",
    "h_max = 1000.0\n",
    "# ---specify the lower bound and upper bound of building footprint prediction by `f_min` and `f_max`, respectively.\n",
    "f_min = 0.0\n",
    "f_max = 1.0\n",
    "\n",
    "# ---specify the settings of cases\n",
    "target_resolution = 100 \n",
    "target_extent = [101.659228,3.108353, 101.701380,3.141738]\n",
    "\n",
    "# ------specify the path of input Sentinel data (note: please use the following format for input data specification)\n",
    "s1_key = \"sentinel_1\"       # key which indicates the path of Sentinel-1's files\n",
    "s2_key = \"sentinel_2\"       # key which indicates the path of Sentinel-2's files\n",
    "\n",
    "input_img = {\n",
    "    \"50pt\": {  # use annual medians as aggregation operation for one year data\n",
    "        s1_key: os.path.join(case_prefix, \"malasia\", \"raw_data\", \"s1.tif\"),      # path of input Sentinel-1 image \n",
    "        s2_key: os.path.join(case_prefix, \"malasia\", \"raw_data\", \"s2.tif\"),      # path of input Sentinel-2 image\n",
    "    }\n",
    "}\n",
    "# ------specify the path of input auxiliary SRTM data (note: please use the following format for input data specification)\n",
    "aux_data = {\n",
    "    \"DEM\": {\n",
    "        \"path\": os.path.join(case_prefix, \"malasia\", \"raw_data\", \"srtm.tif\"),      # path of input SRTM data\n",
    "        \"patch_size_ratio\": 1.0,      # patch size ratio between auxiliary SRTM data and Sentinel data (note: pretrained model offered by SHAFTS uses 1.0 for this parameter)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---specify the information of pretrained models\n",
    "model = \"SEResNet18\"            # name of pretrained models\n",
    "\n",
    "model_directory = os.path.join(\n",
    "    os.path.dirname(case_prefix),\n",
    "    \"src/shafts/dl-models/height/check_pt_{0}_100m_MTL\".format(backbone)\n",
    ")\n",
    "experiment_subdirectory = \"experiment_1\"\n",
    "filename = \"checkpoint.pth.tar\"\n",
    "\n",
    "# Construct the full path to the pretrained model\n",
    "pretrained_model_path = os.path.join(model_directory, experiment_subdirectory, filename)\n",
    "input_patch_size = [20]         # size of input sizes required by pretrained models\n",
    "\n",
    "# ---specify the common settings of prediction\n",
    "padding = 0.005                                  # padding size outside the target region (it is recommended that padding should not be smaller than 0.03)\n",
    "cuda_used = torch.cuda.is_available()           # check whether CUDA can be used for prediction\n",
    "batch_size = 64                                 # batch size for prediction (default: 64)\n",
    "\n",
    "# ---specify the information of output files\n",
    "output_prefix = \"malasia\"\n",
    "output_dir = os.path.join(case_prefix, \"malasia\", \"100m\")\n",
    "output_footprint_file = \"_\".join([output_prefix, \"footprint\", backbone + \"_MTL\"]) + \".tif\"\n",
    "output_footprint_path = os.path.join(output_dir, output_footprint_file)                     # path of output building footprint files\n",
    "output_height_file = \"_\".join([output_prefix, \"height\", backbone + \"_MTL\"]) + \".tif\"\n",
    "output_height_path = os.path.join(output_dir, output_height_file)                           # path of output building height files\n",
    "\n",
    "# ---start our prediction\n",
    "pred_height_from_tiff_DL_patch_MTL(extent=target_extent, out_footprint_file=output_footprint_path, out_height_file=output_height_path, \n",
    "                                        tif_ref=input_img, patch_size=input_patch_size,\n",
    "                                        predictor=model, trained_record=pretrained_model_path, resolution=target_res_mapping[target_resolution],\n",
    "                                        s1_key=s1_key, s2_key=s2_key, \n",
    "                                        aux_feat_info=aux_data, crossed=False, base_dir=tmp_dir, padding=padding, \n",
    "                                        batch_size=batch_size, tmp_suffix=None, log_scale=False,\n",
    "                                        cuda_used=cuda_used, \n",
    "                                        h_min=h_min, h_max=h_max,\n",
    "                                        f_min=f_min, f_max=f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shafts_env_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
